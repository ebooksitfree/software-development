![Cover image for Parallel and High Performance Computing](https://imgdetail.ebookreading.net/cover/cover/202109/EB9781617296468.jpg)

[Parallel and High Performance Computing](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_1.html "Parallel and High Performance Computing")
====================================================================================================================

Release Date : 2021/07/01

ISBN : 9781617296468

Book Description
-----------------

Parallel and High Performance Computing offers techniques guaranteed to boost your code’s effectiveness. You’ll learn to evaluate hardware architectures and work with industry standard tools such as OpenMP and MPI. You’ll master the data structures and algorithms best suited for high performance computing and learn techniques that save energy on handheld devices. You’ll even run a massive tsunami simulation across a bank of GPUs.
  
  

Table of Contents
-----------------

1. [Parallel and High Performance Computing](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_2.html)
1. [Copyright](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_3.html)
1. [Dedication](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_4.html)
1. [contents](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_5.html)
1. [front matter](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_6.html)
    1. [foreword](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_6.html#sigil_toc_id_1)
    1. [Yulie Zamora, University of Chicago, Illinois](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_6.html#sigil_toc_id_2)
    1. [How we came to write this book](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_6.html#sigil_toc_id_3)
    1. [acknowledgments](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_6.html#sigil_toc_id_4)
    1. [about this book](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_6.html#sigil_toc_id_5)
    1. [Who should read this book](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_6.html#sigil_toc_id_6)
1. [Part 1 Introduction to parallel computing](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_7.html)
1. [1 Why parallel computing?](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_8.html)
    1. [1.1 Why should you learn about parallel computing?](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_8.html#sigil_toc_id_14)
    1. [1.1.1 What are the potential benefits of parallel computing?](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_8.html#sigil_toc_id_15)
    1. [1.1.2 Parallel computing cautions](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_8.html#sigil_toc_id_16)
    1. [1.2 The fundamental laws of parallel computing](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_8.html#sigil_toc_id_17)
    1. [1.2.1 The limit to parallel computing: Amdahl’s Law](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_8.html#sigil_toc_id_18)
    1. [1.2.2 Breaking through the parallel limit: Gustafson-Barsis’s Law](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_8.html#sigil_toc_id_19)
    1. [1.3 How does parallel computing work?](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_8.html#sigil_toc_id_20)
    1. [1.3.1 Walking through a sample application](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_8.html#sigil_toc_id_21)
    1. [1.3.2 A hardware model for today’s heterogeneous parallel systems](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_8.html#sigil_toc_id_22)
    1. [1.3.3 The application/software model for today’s heterogeneous parallel systems](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_8.html#sigil_toc_id_23)
    1. [1.4 Categorizing parallel approaches](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_8.html#sigil_toc_id_24)
    1. [1.5 Parallel strategies](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_8.html#sigil_toc_id_25)
    1. [1.6 Parallel speedup versus comparative speedups: Two different measures](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_8.html#sigil_toc_id_26)
    1. [1.7 What will you learn in this book?](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_8.html#sigil_toc_id_27)
    1. [1.7.1 Additional reading](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_8.html#sigil_toc_id_28)
    1. [1.7.2 Exercises](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_8.html#sigil_toc_id_29)
    1. [Summary](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_8.html#sigil_toc_id_30)
1. [2 Planning for parallelization](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_9.html)
    1. [2.1 Approaching a new project: The preparation](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_9.html#sigil_toc_id_31)
    1. [2.1.1 Version control: Creating a safety vault for your parallel code](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_9.html#sigil_toc_id_32)
    1. [2.1.2 Test suites: The first step to creating a robust, reliable application](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_9.html#sigil_toc_id_33)
    1. [2.1.3 Finding and fixing memory issues](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_9.html#sigil_toc_id_34)
    1. [2.1.4 Improving code portability](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_9.html#sigil_toc_id_35)
    1. [2.2 Profiling: Probing the gap between system capabilities and application performance](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_9.html#sigil_toc_id_36)
    1. [2.3 Planning: A foundation for success](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_9.html#sigil_toc_id_37)
    1. [2.3.1 Exploring with benchmarks and mini-apps](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_9.html#sigil_toc_id_38)
    1. [2.3.2 Design of the core data structures and code modularity](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_9.html#sigil_toc_id_39)
    1. [2.3.3 Algorithms: Redesign for parallel](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_9.html#sigil_toc_id_40)
    1. [2.4 Implementation: Where it all happens](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_9.html#sigil_toc_id_41)
    1. [2.5 Commit: Wrapping it up with quality](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_9.html#sigil_toc_id_42)
    1. [2.6 Further explorations](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_9.html#sigil_toc_id_43)
    1. [2.6.1 Additional reading](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_9.html#sigil_toc_id_44)
    1. [2.6.2 Exercises](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_9.html#sigil_toc_id_45)
    1. [Summary](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_9.html#sigil_toc_id_46)
1. [3 Performance limits and profiling](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_10.html)
    1. [3.1 Know your application’s potential performance limits](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_10.html#sigil_toc_id_47)
    1. [3.2 Determine your hardware capabilities: Benchmarking](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_10.html#sigil_toc_id_48)
    1. [3.2.1 Tools for gathering system characteristics](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_10.html#sigil_toc_id_49)
    1. [3.2.2 Calculating theoretical maximum flops](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_10.html#sigil_toc_id_50)
    1. [3.2.3 The memory hierarchy and theoretical memory bandwidth](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_10.html#sigil_toc_id_51)
    1. [3.2.4 Empirical measurement of bandwidth and flops](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_10.html#sigil_toc_id_52)
    1. [3.2.5 Calculating the machine balance between flops and bandwidth](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_10.html#sigil_toc_id_53)
    1. [3.3 Characterizing your application: Profiling](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_10.html#sigil_toc_id_54)
    1. [3.3.1 Profiling tools](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_10.html#sigil_toc_id_55)
    1. [3.3.2 Empirical measurement of processor clock frequency and energy consumption](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_10.html#sigil_toc_id_56)
    1. [3.3.3 Tracking memory during run time](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_10.html#sigil_toc_id_57)
    1. [3.4 Further explorations](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_10.html#sigil_toc_id_58)
    1. [3.4.1 Additional reading](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_10.html#sigil_toc_id_59)
    1. [3.4.2 Exercises](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_10.html#sigil_toc_id_60)
    1. [Summary](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_10.html#sigil_toc_id_61)
1. [4 Data design and performance models](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_11.html)
    1. [4.1 Performance data structures: Data-oriented design](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_11.html#sigil_toc_id_62)
    1. [4.1.1 Multidimensional arrays](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_11.html#sigil_toc_id_63)
    1. [4.1.2 Array of Structures (AoS) versus Structures of Arrays (SoA)](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_11.html#sigil_toc_id_64)
    1. [4.1.3 Array of Structures of Arrays (AoSoA)](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_11.html#sigil_toc_id_65)
    1. [4.2 Three Cs of cache misses: Compulsory, capacity, conflict](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_11.html#sigil_toc_id_66)
    1. [4.3 Simple performance models: A case study](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_11.html#sigil_toc_id_67)
    1. [4.3.1 Full matrix data representations](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_11.html#sigil_toc_id_68)
    1. [4.3.2 Compressed sparse storage representations](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_11.html#sigil_toc_id_69)
    1. [4.4 Advanced performance models](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_11.html#sigil_toc_id_70)
    1. [4.5 Network messages](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_11.html#sigil_toc_id_71)
    1. [4.6 Further explorations](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_11.html#sigil_toc_id_72)
    1. [4.6.1 Additional reading](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_11.html#sigil_toc_id_73)
    1. [4.6.2 Exercises](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_11.html#sigil_toc_id_74)
    1. [Summary](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_11.html#sigil_toc_id_75)
1. [5 Parallel algorithms and patterns](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_12.html)
    1. [5.1 Algorithm analysis for parallel computing applications](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_12.html#sigil_toc_id_76)
    1. [5.2 Performance models versus algorithmic complexity](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_12.html#sigil_toc_id_77)
    1. [5.3 Parallel algorithms: What are they?](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_12.html#sigil_toc_id_78)
    1. [5.4 What is a hash function?](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_12.html#sigil_toc_id_79)
    1. [5.5 Spatial hashing: A highly-parallel algorithm](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_12.html#sigil_toc_id_80)
    1. [5.5.1 Using perfect hashing for spatial mesh operations](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_12.html#sigil_toc_id_81)
    1. [5.5.2 Using compact hashing for spatial mesh operations](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_12.html#sigil_toc_id_82)
    1. [5.6 Prefix sum (scan) pattern and its importance in parallel computing](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_12.html#sigil_toc_id_83)
    1. [5.6.1 Step-efficient parallel scan operation](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_12.html#sigil_toc_id_84)
    1. [5.6.2 Work-efficient parallel scan operation](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_12.html#sigil_toc_id_85)
    1. [5.6.3 Parallel scan operations for large arrays](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_12.html#sigil_toc_id_86)
    1. [5.7 Parallel global sum: Addressing the problem of associativity](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_12.html#sigil_toc_id_87)
    1. [5.8 Future of parallel algorithm research](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_12.html#sigil_toc_id_88)
    1. [5.9 Further explorations](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_12.html#sigil_toc_id_89)
    1. [5.9.1 Additional reading](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_12.html#sigil_toc_id_90)
    1. [5.9.2 Exercises](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_12.html#sigil_toc_id_91)
    1. [Summary](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_12.html#sigil_toc_id_92)
1. [Part 2 CPU: The parallel workhorse](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_13.html)
1. [6 Vectorization: FLOPs for free](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_14.html)
    1. [6.1 Vectorization and single instruction, multiple data (SIMD) overview](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_14.html#sigil_toc_id_93)
    1. [6.2 Hardware trends for vectorization](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_14.html#sigil_toc_id_94)
    1. [6.3 Vectorization methods](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_14.html#sigil_toc_id_95)
    1. [6.3.1 Optimized libraries provide performance for little effort](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_14.html#sigil_toc_id_96)
    1. [6.3.2 Auto-vectorization: The easy way to vectorization speedup (most of the time1)](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_14.html#sigil_toc_id_97)
    1. [6.3.3 Teaching the compiler through hints: Pragmas and directives](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_14.html#sigil_toc_id_98)
    1. [6.3.4 Crappy loops, we got them: Use vector intrinsics](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_14.html#sigil_toc_id_99)
    1. [6.3.5 Not for the faint of heart: Using assembler code for vectorization](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_14.html#sigil_toc_id_100)
    1. [6.4 Programming style for better vectorization](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_14.html#sigil_toc_id_101)
    1. [6.5 Compiler flags relevant for vectorization for various compilers](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_14.html#sigil_toc_id_102)
    1. [6.6 OpenMP SIMD directives for better portability](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_14.html#sigil_toc_id_103)
    1. [6.7 Further explorations](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_14.html#sigil_toc_id_104)
    1. [6.7.1 Additional reading](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_14.html#sigil_toc_id_105)
    1. [6.7.2 Exercises](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_14.html#sigil_toc_id_106)
    1. [Summary](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_14.html#sigil_toc_id_107)
1. [7 OpenMP that performs](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_15.html)
    1. [7.1 OpenMP introduction](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_15.html#sigil_toc_id_108)
    1. [7.1.1 OpenMP concepts](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_15.html#sigil_toc_id_109)
    1. [7.1.2 A simple OpenMP program](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_15.html#sigil_toc_id_110)
    1. [7.2 Typical OpenMP use cases: Loop-level, high-level, and MPI plus OpenMP](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_15.html#sigil_toc_id_111)
    1. [7.2.1 Loop-level OpenMP for quick parallelization](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_15.html#sigil_toc_id_112)
    1. [7.2.2 High-level OpenMP for better parallel performance](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_15.html#sigil_toc_id_113)
    1. [7.2.3 MPI plus OpenMP for extreme scalability](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_15.html#sigil_toc_id_114)
    1. [7.3 Examples of standard loop-level OpenMP](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_15.html#sigil_toc_id_115)
    1. [7.3.1 Loop level OpenMP: Vector addition example](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_15.html#sigil_toc_id_116)
    1. [7.3.2 Stream triad example](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_15.html#sigil_toc_id_117)
    1. [7.3.3 Loop level OpenMP: Stencil example](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_15.html#sigil_toc_id_118)
    1. [7.3.4 Performance of loop-level examples](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_15.html#sigil_toc_id_119)
    1. [7.3.5 Reduction example of a global sum using OpenMP threading](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_15.html#sigil_toc_id_120)
    1. [7.3.6 Potential loop-level OpenMP issues](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_15.html#sigil_toc_id_121)
    1. [7.4 Variable scope importance for correctness in OpenMP](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_15.html#sigil_toc_id_122)
    1. [7.5 Function-level OpenMP: Making a whole function thread parallel](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_15.html#sigil_toc_id_123)
    1. [7.6 Improving parallel scalability with high-level OpenMP](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_15.html#sigil_toc_id_124)
    1. [7.6.1 How to implement high-level OpenMP](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_15.html#sigil_toc_id_125)
    1. [7.6.2 Example of implementing high-level OpenMP](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_15.html#sigil_toc_id_126)
    1. [7.7 Hybrid threading and vectorization with OpenMP](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_15.html#sigil_toc_id_127)
    1. [7.8 Advanced examples using OpenMP](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_15.html#sigil_toc_id_128)
    1. [7.8.1 Stencil example with a separate pass for the x and y directions](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_15.html#sigil_toc_id_129)
    1. [7.8.2 Kahan summation implementation with OpenMP threading](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_15.html#sigil_toc_id_130)
    1. [7.8.3 Threaded implementation of the prefix scan algorithm](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_15.html#sigil_toc_id_131)
    1. [7.9 Threading tools essential for robust implementations](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_15.html#sigil_toc_id_132)
    1. [7.9.1 Using Allinea/ARM MAP to get a quick high-level profile of your application](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_15.html#sigil_toc_id_133)
    1. [7.9.2 Finding your thread race conditions with Intel® Inspector](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_15.html#sigil_toc_id_134)
    1. [7.10 Example of a task-based support algorithm](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_15.html#sigil_toc_id_135)
    1. [7.11 Further explorations](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_15.html#sigil_toc_id_136)
    1. [7.11.1 Additional reading](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_15.html#sigil_toc_id_137)
    1. [7.11.2 Exercises](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_15.html#sigil_toc_id_138)
    1. [Summary](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_15.html#sigil_toc_id_139)
1. [8 MPI: The parallel backbone](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_16.html)
    1. [8.1 The basics for an MPI program](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_16.html#sigil_toc_id_140)
    1. [8.1.1 Basic MPI function calls for every MPI program](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_16.html#sigil_toc_id_141)
    1. [8.1.2 Compiler wrappers for simpler MPI programs](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_16.html#sigil_toc_id_142)
    1. [8.1.3 Using parallel startup commands](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_16.html#sigil_toc_id_143)
    1. [8.1.4 Minimum working example of an MPI program](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_16.html#sigil_toc_id_144)
    1. [8.2 The send and receive commands for process-to-process communication](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_16.html#sigil_toc_id_145)
    1. [8.3 Collective communication: A powerful component of MPI](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_16.html#sigil_toc_id_146)
    1. [8.3.1 Using a barrier to synchronize timers](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_16.html#sigil_toc_id_147)
    1. [8.3.2 Using the broadcast to handle small file input](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_16.html#sigil_toc_id_148)
    1. [8.3.3 Using a reduction to get a single value from across all processes](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_16.html#sigil_toc_id_149)
    1. [8.3.4 Using gather to put order in debug printouts](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_16.html#sigil_toc_id_150)
    1. [8.3.5 Using scatter and gather to send data out to processes for work](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_16.html#sigil_toc_id_151)
    1. [8.4 Data parallel examples](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_16.html#sigil_toc_id_152)
    1. [8.4.1 Stream triad to measure bandwidth on the node](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_16.html#sigil_toc_id_153)
    1. [8.4.2 Ghost cell exchanges in a two-dimensional (2D) mesh](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_16.html#sigil_toc_id_154)
    1. [8.4.3 Ghost cell exchanges in a three-dimensional (3D) stencil calculation](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_16.html#sigil_toc_id_155)
    1. [8.5 Advanced MPI functionality to simplify code and enable optimizations](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_16.html#sigil_toc_id_156)
    1. [8.5.1 Using custom MPI data types for performance and code simplification](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_16.html#sigil_toc_id_157)
    1. [8.5.2 Cartesian topology support in MPI](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_16.html#sigil_toc_id_158)
    1. [8.5.3 Performance tests of ghost cell exchange variants](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_16.html#sigil_toc_id_159)
    1. [8.6 Hybrid MPI plus OpenMP for extreme scalability](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_16.html#sigil_toc_id_160)
    1. [8.6.1 The benefits of hybrid MPI plus OpenMP](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_16.html#sigil_toc_id_161)
    1. [8.6.2 MPI plus OpenMP example](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_16.html#sigil_toc_id_162)
    1. [8.7 Further explorations](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_16.html#sigil_toc_id_163)
    1. [8.7.1 Additional reading](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_16.html#sigil_toc_id_164)
    1. [8.7.2 Exercises](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_16.html#sigil_toc_id_165)
    1. [Summary](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_16.html#sigil_toc_id_166)
1. [Part 3 GPUs: Built to accelerate](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_17.html)
1. [9 GPU architectures and concepts](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_18.html)
    1. [9.1 The CPU-GPU system as an accelerated computational platform](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_18.html#sigil_toc_id_167)
    1. [9.1.1 Integrated GPUs: An underused option on commodity-based systems](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_18.html#sigil_toc_id_168)
    1. [9.1.2 Dedicated GPUs: The workhorse option](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_18.html#sigil_toc_id_169)
    1. [9.2 The GPU and the thread engine](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_18.html#sigil_toc_id_170)
    1. [9.2.1 The compute unit is the streaming multiprocessor (or subslice)](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_18.html#sigil_toc_id_171)
    1. [9.2.2 Processing elements are the individual processors](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_18.html#sigil_toc_id_172)
    1. [9.2.3 Multiple data operations by each processing element](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_18.html#sigil_toc_id_173)
    1. [9.2.4 Calculating the peak theoretical flops for some leading GPUs](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_18.html#sigil_toc_id_174)
    1. [9.3 Characteristics of GPU memory spaces](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_18.html#sigil_toc_id_175)
    1. [9.3.1 Calculating theoretical peak memory bandwidth](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_18.html#sigil_toc_id_176)
    1. [9.3.2 Measuring the GPU stream benchmark](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_18.html#sigil_toc_id_177)
    1. [9.3.3 Roofline performance model for GPUs](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_18.html#sigil_toc_id_178)
    1. [9.3.4 Using the mixbench performance tool to choose the best GPU for a workload](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_18.html#sigil_toc_id_179)
    1. [9.4 The PCI bus: CPU to GPU data transfer overhead](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_18.html#sigil_toc_id_180)
    1. [9.4.1 Theoretical bandwidth of the PCI bus](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_18.html#sigil_toc_id_181)
    1. [9.4.2 A benchmark application for PCI bandwidth](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_18.html#sigil_toc_id_182)
    1. [9.5 Multi-GPU platforms and MPI](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_18.html#sigil_toc_id_183)
    1. [9.5.1 Optimizing the data movement between GPUs across the network](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_18.html#sigil_toc_id_184)
    1. [9.5.2 A higher performance alternative to the PCI bus](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_18.html#sigil_toc_id_185)
    1. [9.6 Potential benefits of GPU-accelerated platforms](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_18.html#sigil_toc_id_186)
    1. [9.6.1 Reducing time-to-solution](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_18.html#sigil_toc_id_187)
    1. [9.6.2 Reducing energy use with GPUs](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_18.html#sigil_toc_id_188)
    1. [9.6.3 Reduction in cloud computing costs with GPUs](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_18.html#sigil_toc_id_189)
    1. [9.7 When to use GPUs](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_18.html#sigil_toc_id_190)
    1. [9.8 Further explorations](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_18.html#sigil_toc_id_191)
    1. [9.8.1 Additional reading](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_18.html#sigil_toc_id_192)
    1. [9.8.2 Exercises](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_18.html#sigil_toc_id_193)
    1. [Summary](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_18.html#sigil_toc_id_194)
1. [10 GPU programming model](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_19.html)
    1. [10.1 GPU programming abstractions: A common framework](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_19.html#sigil_toc_id_195)
    1. [10.1.1 Massive parallelism](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_19.html#sigil_toc_id_196)
    1. [10.1.2 Inability to coordinate among tasks](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_19.html#sigil_toc_id_197)
    1. [10.1.3 Terminology for GPU parallelism](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_19.html#sigil_toc_id_198)
    1. [10.1.4 Data decomposition into independent units of work: An NDRange or grid](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_19.html#sigil_toc_id_199)
    1. [10.1.5 Work groups provide a right-sized chunk of work](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_19.html#sigil_toc_id_200)
    1. [10.1.6 Subgroups, warps, or wavefronts execute in lockstep](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_19.html#sigil_toc_id_201)
    1. [10.1.7 Work item: The basic unit of operation](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_19.html#sigil_toc_id_202)
    1. [10.1.8 SIMD or vector hardware](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_19.html#sigil_toc_id_203)
    1. [10.2 The code structure for the GPU programming model](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_19.html#sigil_toc_id_204)
    1. [10.2.1 “Me” programming: The concept of a parallel kernel](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_19.html#sigil_toc_id_205)
    1. [10.2.2 Thread indices: Mapping the local tile to the global world](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_19.html#sigil_toc_id_206)
    1. [10.2.3 Index sets](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_19.html#sigil_toc_id_207)
    1. [10.2.4 How to address memory resources in your GPU programming model](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_19.html#sigil_toc_id_208)
    1. [10.3 Optimizing GPU resource usage](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_19.html#sigil_toc_id_209)
    1. [10.3.1 How many registers does my kernel use?](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_19.html#sigil_toc_id_210)
    1. [10.3.2 Occupancy: Making more work available for work group scheduling](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_19.html#sigil_toc_id_211)
    1. [10.4 Reduction pattern requires synchronization across work groups](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_19.html#sigil_toc_id_212)
    1. [10.5 Asynchronous computing through queues (streams)](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_19.html#sigil_toc_id_213)
    1. [10.6 Developing a plan to parallelize an application for GPUs](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_19.html#sigil_toc_id_214)
    1. [10.6.1 Case 1: 3D atmospheric simulation](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_19.html#sigil_toc_id_215)
    1. [10.6.2 Case 2: Unstructured mesh application](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_19.html#sigil_toc_id_216)
    1. [10.7 Further explorations](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_19.html#sigil_toc_id_217)
    1. [10.7.1 Additional reading](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_19.html#sigil_toc_id_218)
    1. [10.7.2 Exercises](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_19.html#sigil_toc_id_219)
    1. [Summary](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_19.html#sigil_toc_id_220)
1. [11 Directive-based GPU programming](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_20.html)
    1. [11.1 Process to apply directives and pragmas for a GPU implementation](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_20.html#sigil_toc_id_221)
    1. [11.2 OpenACC: The easiest way to run on your GPU](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_20.html#sigil_toc_id_222)
    1. [11.2.1 Compiling OpenACC code](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_20.html#sigil_toc_id_223)
    1. [11.2.2 Parallel compute regions in OpenACC for accelerating computations](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_20.html#sigil_toc_id_224)
    1. [11.2.3 Using directives to reduce data movement between the CPU and the GPU](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_20.html#sigil_toc_id_225)
    1. [11.2.4 Optimizing the GPU kernels](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_20.html#sigil_toc_id_226)
    1. [11.2.5 Summary of performance results for the stream triad](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_20.html#sigil_toc_id_227)
    1. [11.2.6 Advanced OpenACC techniques](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_20.html#sigil_toc_id_228)
    1. [11.3 OpenMP: The heavyweight champ enters the world of accelerators](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_20.html#sigil_toc_id_229)
    1. [11.3.1 Compiling OpenMP code](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_20.html#sigil_toc_id_230)
    1. [11.3.2 Generating parallel work on the GPU with OpenMP](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_20.html#sigil_toc_id_231)
    1. [11.3.3 Creating data regions to control data movement to the GPU with OpenMP](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_20.html#sigil_toc_id_232)
    1. [11.3.4 Optimizing OpenMP for GPUs](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_20.html#sigil_toc_id_233)
    1. [11.3.5 Advanced OpenMP for GPUs](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_20.html#sigil_toc_id_234)
    1. [11.4 Further explorations](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_20.html#sigil_toc_id_235)
    1. [11.4.1 Additional reading](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_20.html#sigil_toc_id_236)
    1. [11.4.2 Exercises](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_20.html#sigil_toc_id_237)
    1. [Summary](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_20.html#sigil_toc_id_238)
1. [12 GPU languages: Getting down to basics](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_21.html)
    1. [Figure 12.1 The interoperability map for the GPU languages shows an increasingly complex situation. Four GPU languages are shown at the top with the various hardware devices at the bottom. The arrows ](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_21.html#sigil_toc_id_239)
    1. [12.1 Features of a native GPU programming language](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_21.html#sigil_toc_id_240)
    1. [12.2 CUDA and HIP GPU languages: The low-level performance option](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_21.html#sigil_toc_id_241)
    1. [12.2.1 Writing and building your first CUDA application](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_21.html#sigil_toc_id_242)
    1. [12.2.2 A reduction kernel in CUDA: Life gets complicated](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_21.html#sigil_toc_id_243)
    1. [Figure 12.2 Pair-wise reduction tree for a warp that sums up values in log n steps.](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_21.html#sigil_toc_id_244)
    1. [12.2.3 Hipifying the CUDA code](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_21.html#sigil_toc_id_245)
    1. [12.3 OpenCL for a portable open source GPU language](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_21.html#sigil_toc_id_246)
    1. [12.3.1 Writing and building your first OpenCL application](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_21.html#sigil_toc_id_247)
    1. [12.3.2 Reductions in OpenCL](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_21.html#sigil_toc_id_248)
    1. [Figure 12.3 Comparison of OpenCL and CUDA reduction kernels: sum_within_block](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_21.html#sigil_toc_id_249)
    1. [Figure 12.4 Comparison for the first of two kernel passes for the OpenCL and CUDA reduction kernels](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_21.html#sigil_toc_id_250)
    1. [Figure 12.5 Comparison of the second pass for the reduction sum](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_21.html#sigil_toc_id_251)
    1. [12.4 SYCL: An experimental C++ implementation goes mainstream](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_21.html#sigil_toc_id_252)
    1. [12.5 Higher-level languages for performance portability](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_21.html#sigil_toc_id_253)
    1. [12.5.1 Kokkos: A performance portability ecosystem](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_21.html#sigil_toc_id_254)
    1. [12.5.2 RAJA for a more adaptable performance portability layer](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_21.html#sigil_toc_id_255)
    1. [12.6 Further explorations](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_21.html#sigil_toc_id_256)
    1. [12.6.1 Additional reading](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_21.html#sigil_toc_id_257)
    1. [12.6.2 Exercises](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_21.html#sigil_toc_id_258)
    1. [Summary](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_21.html#sigil_toc_id_259)
1. [13 GPU profiling and tools](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_22.html)
    1. [13.1 An overview of profiling tools](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_22.html#sigil_toc_id_260)
    1. [13.2 How to select a good workflow](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_22.html#sigil_toc_id_261)
    1. [13.3 Example problem: Shallow water simulation](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_22.html#sigil_toc_id_262)
    1. [13.4 A sample of a profiling workflow](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_22.html#sigil_toc_id_263)
    1. [13.4.1 Run the shallow water application](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_22.html#sigil_toc_id_264)
    1. [13.4.2 Profile the CPU code to develop a plan of action](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_22.html#sigil_toc_id_265)
    1. [13.4.3 Add OpenACC compute directives to begin the implementation step](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_22.html#sigil_toc_id_266)
    1. [13.4.4 Add data movement directives](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_22.html#sigil_toc_id_267)
    1. [13.4.5 Guided analysis can give you some suggested improvements](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_22.html#sigil_toc_id_268)
    1. [13.4.6 The NVIDIA Nsight suite of tools can be a powerful development aid](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_22.html#sigil_toc_id_269)
    1. [13.4.7 CodeXL for the AMD GPU ecosystem](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_22.html#sigil_toc_id_270)
    1. [13.5 Don’t get lost in the swamp: Focus on the important metrics](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_22.html#sigil_toc_id_271)
    1. [13.5.1 Occupancy: Is there enough work?](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_22.html#sigil_toc_id_272)
    1. [13.5.2 Issue efficiency: Are your warps on break too often?](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_22.html#sigil_toc_id_273)
    1. [13.5.3 Achieved bandwidth: It always comes down to bandwidth](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_22.html#sigil_toc_id_274)
    1. [13.6 Containers and virtual machines provide alternate workflows](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_22.html#sigil_toc_id_275)
    1. [13.6.1 Docker containers as a workaround](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_22.html#sigil_toc_id_276)
    1. [13.6.2 Virtual machines using VirtualBox](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_22.html#sigil_toc_id_277)
    1. [13.7 Cloud options: A flexible and portable capability](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_22.html#sigil_toc_id_278)
    1. [13.8 Further explorations](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_22.html#sigil_toc_id_279)
    1. [13.8.1 Additional reading](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_22.html#sigil_toc_id_280)
    1. [13.8.2 Exercises](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_22.html#sigil_toc_id_281)
    1. [Summary](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_22.html#sigil_toc_id_282)
1. [Part 4 High performance computing ecosystems](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_23.html)
1. [14 Affinity: Truce with the kernel](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_24.html)
    1. [14.1 Why is affinity important?](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_24.html#sigil_toc_id_283)
    1. [14.2 Discovering your architecture](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_24.html#sigil_toc_id_284)
    1. [14.3 Thread affinity with OpenMP](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_24.html#sigil_toc_id_285)
    1. [14.4 Process affinity with MPI](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_24.html#sigil_toc_id_286)
    1. [14.4.1 Default process placement with OpenMPI](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_24.html#sigil_toc_id_287)
    1. [14.4.2 Taking control: Basic techniques for specifying process placement in OpenMPI](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_24.html#sigil_toc_id_288)
    1. [14.4.3 Affinity is more than just process binding: The full picture](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_24.html#sigil_toc_id_289)
    1. [14.5 Affinity for MPI plus OpenMP](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_24.html#sigil_toc_id_290)
    1. [14.6 Controlling affinity from the command line](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_24.html#sigil_toc_id_291)
    1. [14.6.1 Using hwloc-bind to assign affinity](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_24.html#sigil_toc_id_292)
    1. [14.6.2 Using likwid-pin: An affinity tool in the likwid tool suite](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_24.html#sigil_toc_id_293)
    1. [14.7 The future: Setting and changing affinity at run time](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_24.html#sigil_toc_id_294)
    1. [14.7.1 Setting affinities in your executable](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_24.html#sigil_toc_id_295)
    1. [14.7.2 Changing your process affinities during run time](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_24.html#sigil_toc_id_296)
    1. [14.8 Further explorations](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_24.html#sigil_toc_id_297)
    1. [14.8.1 Additional reading](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_24.html#sigil_toc_id_298)
    1. [14.8.2 Exercises](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_24.html#sigil_toc_id_299)
    1. [Summary](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_24.html#sigil_toc_id_300)
1. [15 Batch schedulers:Bringing order to chaos](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_25.html)
    1. [15.1 The chaos of an unmanaged system](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_25.html#sigil_toc_id_301)
    1. [15.2 How not to be a nuisance when working on a busy cluster](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_25.html#sigil_toc_id_302)
    1. [15.2.1 Layout of a batch system for busy clusters](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_25.html#sigil_toc_id_303)
    1. [15.2.2 How to be courteous on busy clusters and HPC sites: Common HPC pet peeves](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_25.html#sigil_toc_id_304)
    1. [15.3 Submitting your first batch script](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_25.html#sigil_toc_id_305)
    1. [15.4 Automatic restarts for long-running jobs](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_25.html#sigil_toc_id_306)
    1. [15.5 Specifying dependencies in batch scripts](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_25.html#sigil_toc_id_307)
    1. [15.6 Further explorations](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_25.html#sigil_toc_id_308)
    1. [15.6.1 Additional reading](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_25.html#sigil_toc_id_309)
    1. [15.6.2 Exercises](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_25.html#sigil_toc_id_310)
    1. [Summary](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_25.html#sigil_toc_id_311)
1. [16 File operations for a parallel world](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_26.html)
    1. [16.1 The components of a high-performance filesystem](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_26.html#sigil_toc_id_312)
    1. [16.2 Standard file operations: A parallel-to-serial interface](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_26.html#sigil_toc_id_313)
    1. [16.3 MPI file operations (MPI-IO) for a more parallel world](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_26.html#sigil_toc_id_314)
    1. [16.4 HDF5 is self-describing for better data management](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_26.html#sigil_toc_id_315)
    1. [16.5 Other parallel file software packages](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_26.html#sigil_toc_id_316)
    1. [16.6 Parallel filesystem: The hardware interface](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_26.html#sigil_toc_id_317)
    1. [16.6.1 Everything you wanted to know about your parallel file setup but didn’t know how to ask](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_26.html#sigil_toc_id_318)
    1. [16.6.2 General hints that apply to all filesystems](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_26.html#sigil_toc_id_319)
    1. [16.6.3 Hints specific to particular filesystems](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_26.html#sigil_toc_id_320)
    1. [16.7 Further explorations](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_26.html#sigil_toc_id_321)
    1. [16.7.1 Additional reading](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_26.html#sigil_toc_id_322)
    1. [16.7.2 Exercises](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_26.html#sigil_toc_id_323)
    1. [Summary](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_26.html#sigil_toc_id_324)
1. [17 Tools and resources for better code](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_27.html)
    1. [17.1 Version control systems: It all begins here](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_27.html#sigil_toc_id_325)
    1. [17.1.1 Distributed version control fits the more mobile world](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_27.html#sigil_toc_id_326)
    1. [17.1.2 Centralized version control for simplicity and code security](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_27.html#sigil_toc_id_327)
    1. [17.2 Timer routines for tracking code performance](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_27.html#sigil_toc_id_328)
    1. [17.3 Profilers: You can’t improve what you don’t measure](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_27.html#sigil_toc_id_329)
    1. [17.3.1 Simple text-based profilers for everyday use](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_27.html#sigil_toc_id_330)
    1. [17.3.2 High-level profilers for quickly identifying bottlenecks](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_27.html#sigil_toc_id_331)
    1. [17.3.3 Medium-level profilers to guide your application development](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_27.html#sigil_toc_id_332)
    1. [17.3.4 Detailed profilers give the gory details of hardware performance](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_27.html#sigil_toc_id_333)
    1. [17.4 Benchmarks and mini-apps: A window into system performance](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_27.html#sigil_toc_id_334)
    1. [17.4.1 Benchmarks measure system performance characteristics](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_27.html#sigil_toc_id_335)
    1. [17.4.2 Mini-apps give the application perspective](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_27.html#sigil_toc_id_336)
    1. [17.5 Detecting (and fixing) memory errors for a robust application](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_27.html#sigil_toc_id_337)
    1. [17.5.1 Valgrind Memcheck: The open source standby](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_27.html#sigil_toc_id_338)
    1. [17.5.2 Dr. Memory for your memory ailments](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_27.html#sigil_toc_id_339)
    1. [17.5.3 Commercial memory tools for demanding applications](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_27.html#sigil_toc_id_340)
    1. [17.5.4 Compiler-based memory tools for convenience](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_27.html#sigil_toc_id_341)
    1. [17.5.5 Fence-post checkers detect out-of-bounds memory accesses](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_27.html#sigil_toc_id_342)
    1. [17.5.6 GPU memory tools for robust GPU applications](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_27.html#sigil_toc_id_343)
    1. [17.6 Thread checkers for detecting race conditions](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_27.html#sigil_toc_id_344)
    1. [17.6.1 Intel® Inspector: A race condition detection tool with a GUI](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_27.html#sigil_toc_id_345)
    1. [17.6.2 Archer: A text-based tool for detecting race conditions](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_27.html#sigil_toc_id_346)
    1. [17.7 Bug-busters: Debuggers to exterminate those bugs](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_27.html#sigil_toc_id_347)
    1. [17.7.1 TotalView debugger is widely available at HPC sites](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_27.html#sigil_toc_id_348)
    1. [17.7.2 DDT is another debugger widely available at HPC sites](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_27.html#sigil_toc_id_349)
    1. [17.7.3 Linux debuggers: Free alternatives for your local development needs](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_27.html#sigil_toc_id_350)
    1. [17.7.4 GPU debuggers can help crush those GPU bugs](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_27.html#sigil_toc_id_351)
    1. [17.8 Profiling those file operations](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_27.html#sigil_toc_id_352)
    1. [17.9 Package managers: Your personal system administrator](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_27.html#sigil_toc_id_353)
    1. [17.9.1 Package managers for macOS](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_27.html#sigil_toc_id_354)
    1. [17.9.2 Package managers for Windows](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_27.html#sigil_toc_id_355)
    1. [17.9.3 The Spack package manager: A package manager for high performance computing](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_27.html#sigil_toc_id_356)
    1. [17.10 Modules: Loading specialized toolchains](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_27.html#sigil_toc_id_357)
    1. [17.10.1 TCL modules: The original modules system for loading software toolchains](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_27.html#sigil_toc_id_358)
    1. [17.10.2 Lmod: A Lua-based alternative Modules implementation](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_27.html#sigil_toc_id_359)
    1. [17.11 Reflections and exercises](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_27.html#sigil_toc_id_360)
    1. [Summary](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_27.html#sigil_toc_id_361)
1. [appendix A References](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_28.html)
1. [appendix B Solutions to exercises](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_29.html)
1. [appendix C Glossary](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_30.html)
1. [index](https://ebookreading.net/view/book/Parallel+and+High+Performance+Computing-EB9781617296468_31.html)
